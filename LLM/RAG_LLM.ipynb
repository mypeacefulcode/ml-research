{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHbg7vj504GwixPPCPSRQo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv7ZKLOFqzOP"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈을 설치합니다.\n",
        "!pip install langchain openai chromadb html2text tiktoken sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatGPT를 이용하기 위해서는 api key가 필요합니다.\n",
        "# 필요한 api key는 https://platform.openai.com에서 무료로 발급 받을수 있습니다.\n",
        "# Google 검색을 위해서는 Google api key와 cse id가 필요합니다.\n",
        "# api key는 Google cloud에서 cse id는 https://programmablesearchengine.google.com 에서 무료로 발급받을 수 있습니다.\n",
        "GOOGLE_CSE_ID = \"...\"\n",
        "OPENAI_API_KEY = \"...\"\n",
        "GOOGLE_API_KEY = \"...\""
      ],
      "metadata": {
        "id": "uhHarEgLq60v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.retrievers.web_research import WebResearchRetriever\n",
        "from langchain.chains import RetrievalQAWithSourcesChain, LLMChain\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "class ConversationLLM:\n",
        "  def __init__(self):\n",
        "    self.llm = ChatOpenAI()\n",
        "    self.search = GoogleSearchAPIWrapper()\n",
        "    self.prompt = PromptTemplate.from_template(\"{question}\")\n",
        "\n",
        "  def set_chain(self, model_name):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model_kwargs = {'device': device}\n",
        "    # Embedding 모델은 HuggingFace를 이용합니다.\n",
        "    hf = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs\n",
        "    )\n",
        "\n",
        "    # Chroma를 백터 스토리지로 사용합니다.\n",
        "    vectorstore = Chroma(embedding_function=hf)\n",
        "    # 검색결과가 임베딩되어 저장됩니다.\n",
        "    web_search = WebResearchRetriever.from_llm(\n",
        "        vectorstore=vectorstore,\n",
        "        llm=self.llm,\n",
        "        search=self.search\n",
        "    )\n",
        "\n",
        "    # RAG를 사용하는 체인과 아닌 체인을 각각 만듭니다.\n",
        "    self.rag_chain = RetrievalQAWithSourcesChain.from_chain_type(self.llm, retriever=web_search)\n",
        "    self.chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
        "\n",
        "  # RAG 사용여부를 옵션으로 정합니다.\n",
        "  def question(self, q, rag=False):\n",
        "    return self.rag_chain({\"question\":q})['answer'] if rag else self.chain({\"question\":q})['text']\n",
        "\n",
        "conversation_llm = ConversationLLM()\n",
        "# HuggingFace에서 사용할 모델을 선택합니다.\n",
        "# 여기서는 구글 다국어 Bert모델을 사용합니다.\n",
        "conversation_llm.set_chain(\"bert-base-multilingual-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV9yyPzbrFa1",
        "outputId": "df5400ac-b168-4624-ff28-e321073a6475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/bert-base-multilingual-uncased. Creating a new one with MEAN pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT3.5는 2023년 데이터가 없으므로 2023년 질문에 대답하지 못합니다.\n",
        "q = \"2023년 아시안게임 축구 금메달은 어느나라인지 말해줘\"\n",
        "conversation_llm.question(q, rag=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "O9DFRTHV18zb",
        "outputId": "762fc971-a927-45c7-fe1a-c89c1091f7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2023년 아시안게임 축구 금메달은 아직 결정되지 않았으며, 예측할 수 없습니다. 아시안게임은 매번 다양한 국가들이 경기를 펼치기 때문에 누가 금메달을 따를지는 경기 진행 상황에 따라 결정됩니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색으로 2023년 아시안게임 결과를 알려주니 잘 대답합니다.\n",
        "conversation_llm.question(q, rag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Ubet5HA3C1Iv",
        "outputId": "392dbb4f-1aab-4df9-b270-c773999d6cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2023년 아시안게임 축구 금메달은 한국 대표팀입니다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}